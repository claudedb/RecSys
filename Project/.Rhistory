1+1
help(qunif)
qunif(1)
qunif(1=0.75)
qunif(0.75)
install.packages('xgboost')
source('~/Polymtl/LOG6308/clustering.R', echo=TRUE)
dim(dist_eucl)
clusters<-hclust(dist_eucl,method='complete')
View(dist_eucl)
dist_eucl<-sqrt(sweep(sweep(-2*m %*% t(m),1,sums_2,"+"),2,sums_2,"+"))
clusters<-hclust(dist_eucl,method='complete')
clusters<-hclust(as.dist(dist_eucl),method='complete')
clusters
try<-cutree(clusters, k = 10)
try
clusters<-hclust(as.dist(dist_eucl),method='centroid')
try<-cutree(clusters, k = 10)
try
clusters<-hclust(as.dist(dist_eucl))
try<-cutree(clusters, k = 10)
try
dist_eucl<-matrix.cos(m)
matrix.cos <- function(m) {
(m %*% t(m)) / ( t(matrix(sqrt(rowSums(m^2)),nrow(m),nrow(m)))
* (sqrt(rowSums(m^2))) )
}
sums_2<-rowSums(m^2)
dist_eucl<-matrix.cos(m)
clusters<-hclust(as.dist(dist_eucl))
try<-cutree(clusters, k = 10)
try
avg.user<-rowSums(m)/rowSums(m>0)
m.class<-cbind(calc.clusters,m)
calc.clusters<-cutree(clusters, k = 10)
m.class<-cbind(calc.clusters,m)
View(m.class)
clusters.avg<-aggregate(.~calc.clusters,m.class,mean())
clusters.avg<-aggregate(.~calc.clusters,m.class,'mean')
m.class<-as.dataframe(cbind(calc.clusters,m))
m.class<-as.data.frame(cbind(calc.clusters,m))
clusters.avg<-aggregate(.~calc.clusters,m.class,'mean')
View(clusters.avg)
clusters.avg<-aggregate(.~calc.clusters,m.class,'sum')/aggregate(.~calc.clusters,m.class>0,'sum')
View(m.class)
m.class[m.class==0]<-NA
clusters.avg<-aggregate(.~calc.clusters,m.class,'mean')
mean.nona<-function(m){
return(mean(m,na.rm=T))
}
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean.nona')
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
calc.clusters<-cutree(clusters, k = 10)
m.class<-as.data.frame(cbind(calc.clusters,m))
m.class[m.class==0]<-NA
mean.nona<-function(m){
return(mean(m,na.rm=T))
}
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
m.class<-as.data.frame(cbind(calc.clusters,m))
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
m.class[m.class==0]<-NA
View(m.class)
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.rm=T,na.action=NULL)
View(clusters.avg)
is.nan(clusters.avg)<-NA
is.nan(clusters.avg)
source('~/GitHub/LOG6308/TP 2/TP2-V1.R', echo=TRUE)
which(m[doc.id.q1,]==1)
s
S
SS<-colSums(which(m[doc.id.q1,]==1))
SS<-colSums(m[which(m[doc.id.q1,]==1),])
ss
SS
SS<-colSums(m[which(m[doc.id.q1,]==1),])+m[,doc.id.q1]
SS<-colSums(m[which(m[doc.id.q1,]==1),])+m[doc.id.q1,]
SS[SS>=1]<-1
ref.ref.PR<-S.prime*PageRank
S.prime<-colSums(m[which(m[doc.id.q1,]==1),])+m[doc.id.q1,]
S.prime[S.prime>=1]<-1
ref.ref.PR<-S.prime*PageRank
m[doc.id.q1,]
RR.PageRank<-S.prime*PageRank
RR.PageRank<-S.prime*PageRank
recommendations.RR<-RR.PageRank[order(-recommendations.RR)][1:10]
recommendations.RR<-RR.PageRank[order(-RR.PageRank)][1:10]
colnames(recommendations.RR)
colnames(recommendations.references)
S
references.PageRank<-m[doc.id.q1,]*PageRank
recommendations.references<-references.PageRank[order(-references.PageRank)][1:10]
colnames(recommendations.references)
S.prime<-colSums(m[which(m[doc.id.q1,]==1),])+m[doc.id.q1,]
S.prime[S.prime>=1]<-1
RR.PageRank<-S.prime*PageRank
recommendations.RR<-RR.PageRank[order(-RR.PageRank)][1:10]
colnames(recommendations.RR)
colnames(recommendations.references)
vecteur.q2<-m[,doc.id.q1]
vecteur.q2<-m[,"x"+doc.id.q1]
doc.id.q2<-"X"+doc.id.q1
doc.id.q2<-paste("X",doc.id.q1)
doc.id.q2<-paste("X",doc.id.q1,sep="")
vecteur.q2<-m[,doc.id.q2]
positions.votes.communs=(m[,doc.id.q2]*m)>0
positions.votes.communs<-(m[,doc.id.q2]*m)>0
votes.communs<-(colSums((m[,doc.id.q2]*m)>0,na.rm=T))
doc.id.q2<-paste("X",doc.id.q1,sep="")
vecteur.q2<-m[,doc.id.q2]
#On identifie d'abord avec une matrice logique les positions des votes communs avec l'article actuel
positions.votes.communs<-(m[,doc.id.q2]*m)>0
#votes.communs est un vecteur de longueur 1090 où chaque instance représente le nombre de votes communs avec l'article actuel.
votes.communs<-(colSums((m[,doc.id.q2]*m)>0,na.rm=T))
k<-vecteur.q2%*%m
m.clean<-m
m.clean[!positions.votes.communs]<-NA
vecteur.q2.clean<-vecteur.q2
vecteur.q2.clean<-matrix(vecteur.q2.clean,nrow=dim(m)[1],ncol=dim(m)[2])
vecteur.q2.clean<-as(vecteur.q2.clean, "dgCMatrix")
vecteur.q2.clean[!positions.votes.communs]=NA
n=sqrt(colSums(m.clean^2,na.rm=T))
d=sqrt(colSums(vecteur.q2.clean^2,na.rm=T))
cosinus.q2<-k/(n*d)
cosinus.q2<-as.vector(cosinus.q2)
cosinus.q2[is.nan(cosinus.q2)]<-0
#Paramètre à modifier parce que si il n'est pas là, tous les articles avec les plus hauts cosinus sont ceux
#qui n'ont pas beaucoup de votes communs et que les votes sont très similaires
cosinus.q2.VC<-cosinus.q2
#cosinus.q2.VC[votes.communs<=15]<-NA
distance.ii<-sqrt(colSums((m.clean-vecteur.q3)^2,na.rm=T))/votes.communs
distance.ii[votes.communs<5]<-NA
#On sélectionne les 20 items les plus proches et
distance.top20.ii<-min.nindex(distance.ii,21)
distance.top20.ii<-distance.top20.ii[distance.top20.ii!=q2.id]
cosinus.q3=cosinus.q2[distance.top20.ii]
#On apporte une pondération fonction du nombre de votes communs avec Star trek
cosinus.q2.VC=(pmax(votes.communs[distance.top20.ii],5)/5)*cosinus.q2[distance.top20.ii]
facteur.k<-1/sum(abs(cosinus.q2.VC),na.rm=T)
avg.article<-sum(m[,doc.id.q2])/sum(m[,doc.id.q2]>0)
#m.estim représente la matrice m qu'on a filtré avec les 20 plus proches voisins, elle est donc de dimension 1090x20.
m.estim<-m
m.estim[m.estim==0]<-NA
m.estim<-m.estim[,distance.top20.ii]
#Calcul de l'Estimation du vote basé sur les plus proches voisins
ecart=t(t(m.estim)-colMeans(m.estim,na.rm=T))
ecart.mat=as.matrix(ecart)
terme=t(t(ecart.mat)*cosinus.q2.VC)
#On prédit même pour ceux ayant déjà un vote pour l'article
estimation=avg.startrek+facteur.k*rowSums(terme,na.rm=T)
#On donne une valeur manquante aux users qui n'ont pas de votes communs avec les 20 plus proches voisins du film actuel
estimation[which(rowSums(m.estim,na.rm=T)==0)]=NA
doc.id.q2<-paste("X",doc.id.q1,sep="")
vecteur.q2<-m[,doc.id.q2]
positions.votes.communs<-(m[,doc.id.q2]*m)>0
votes.communs<-(colSums((m[,doc.id.q2]*m)>0,na.rm=T))
k<-vecteur.q2%*%m
k<-vecteur.q2%*%as.matrix(m)
m.clean<-as.matrix(m)
m.clean[!positions.votes.communs]<-NA
vecteur.q2.clean<-vecteur.q2
vecteur.q2.clean<-matrix(vecteur.q2.clean,nrow=dim(m)[1],ncol=dim(m)[2])
vecteur.q2.clean<-as(vecteur.q2.clean, "dgCMatrix")
vecteur.q2.clean[!positions.votes.communs]=NA
n=sqrt(colSums(m.clean^2,na.rm=T))
d=sqrt(colSums(vecteur.q2.clean^2,na.rm=T))
cosinus.q2<-k/(n*d)
cosinus.q2<-as.vector(cosinus.q2)
cosinus.q2[is.nan(cosinus.q2)]<-0
cosinus.q2.VC<-cosinus.q2
distance.ii<-sqrt(colSums((m.clean-vecteur.q3)^2,na.rm=T))/votes.communs
distance.ii<-sqrt(colSums((m.clean-vecteur.q2)^2,na.rm=T))/votes.communs
distance.ii[votes.communs<5]<-NA
distance.top20.ii<-min.nindex(distance.ii,21)
distance.top20.ii<-distance.top20.ii[distance.top20.ii!=q2.id]
cosinus.q2<-cosinus.q2[distance.top20.ii]
cosinus.q2.VC=(pmax(votes.communs[distance.top20.ii],5)/5)*cosinus.q2[distance.top20.ii]
facteur.k<-1/sum(abs(cosinus.q2.VC),na.rm=T)
avg.article<-sum(m[,doc.id.q2])/sum(m[,doc.id.q2]>0)
m.estim<-as.matrix(m)
m.estim[m.estim==0]<-NA
m.estim<-m.estim[,distance.top20.ii]
ecart=t(t(m.estim)-colMeans(m.estim,na.rm=T))
ecart.mat=as.matrix(ecart)
terme=t(t(ecart.mat)*cosinus.q2.VC)
estimation=avg.article+facteur.k*rowSums(terme,na.rm=T)
estimation[which(rowSums(m.estim,na.rm=T)==0)]=NA
estimation
cosinus.q2
cosinus.q2<-cosinus.vm(vecteur.q2,m)
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); (v %*% m)/(n * sqrt(sum(v^2)))
return(n)
}
cosinus.q2<-cosinus.vm(vecteur.q2,m)
cosinus.q2<-cosinus.vm(vecteur.q2,as.matrix(m))
recommendations.ii<-cosinus.q2[order(-cosinus.q2)][1:10]
colnames(cosinus.q2)
cosinus.q2
colnames(recommendations.ii)
recommendations.ii<-cosinus.q2[order(-cosinus.q2)][1:10]
rownames(recommendations.ii)
recommendations.ii
recommendations.ii[1,]
colnames(recommendations.ii)
colnames(data.frame(recommendations.ii))
data.frame(recommendations.ii)
rownames(data.frame(recommendations.ii))
colnames(recommendations.RR)
colnames(recommendations.references)
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
X.lsa.tfidf <- lsaSpace.tfidf$T %*% diag(lsaSpace.tfidf$S)
lsaSpace.tfidf
lsa.startTime <- Sys.time()
lsaSpace.tfidf <- lsa(tf.idf,dims=dimcalc_share())
#lsaSpace.tfidf <- as.textmatrix(lsaSpace.tfidf)
lsaSpace.entropy <- lsa(log.entropy, dims=dimcalc_share())
#lsaSpace.entropy <- as.textmatrix(lsaSpace.entropy)
lsa.endTime <- Sys.time()
lsa.elapsedTime <- lsa.endTime-lsa.startTime
lsa.elapsedTimes
lsa.elapsedTimes
lsa.elapsedTime <- lsa.endTime-lsa.startTime
lsa.elapsedTimes
lsa.elapsedTime
X.lsa.tfidf <- lsaSpace.tfidf$T %*% diag(lsaSpace.tfidf$S)
X.lsa.tfidf <- lsaSpace.tfidf$tk %*% diag(lsaSpace.tfidf$sk)
X.lsa.tfidf
View(text.data)
View(courses.data)
View(term.count)
dim(X.lsa.tfidf)
term.count <- text.data[id.poly,.(total=sum(n)),by = terms.id ]
term.count
term.count$terms <- terms.data[term.count$terms.id, ]
term.count
X.lsa.tfidf <- lsaSpace.tfidf$tk %*% diag(lsaSpace.tfidf$sk) %*% t(lsaSpace.tfidf$dk)
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
term.count <- text.data[id.poly,.(total=sum(n),count = .N),by = terms.id ]
term.count$terms <- terms.data[term.count$terms.id, ]
term.count
View(term.count)
View(terms.data)
term.count <- text.data[id.poly,.(total=sum(n),count = .N),by = terms.id ]
term.count <- text.data[id.poly,.(total=sum(n)),by = terms.id ]
term.count <- text.data[id.poly,.(total=sum(n)),by = terms.id ]
m.poly <- m.text[,id.poly]
term.count <- text.data[id.poly,.(total=sum(n)),by = terms.id ]
m.poly <- m.text[,id.poly]
dim(m.poly)
m.poly
View(text.data)
term.count <- text.data[couses.id %in% id.poly,.(total=sum(n)),by = terms.id ]
term.count <- text.data[courses.id %in% id.poly,.(total=sum(n)),by = terms.id ]
View(term.count)
m.poly<-m.poly[rowSums(m.poly) > 0,]
term.count <- text.data[courses.id %in% id.poly,.(total=sum(n)),by = terms.id ]
term.count <- text.data[courses.id %in% id.poly,.(total=sum(n)),by = terms.id ]
term.count$term <- terms.data[term.count$terms.id]
term.count$term <- terms.data[term.count$terms.id,]
term.count <- text.data[courses.id %in% id.poly,.(total=sum(n),count=.N),by = terms.id ]
term.count$term <- terms.data[term.count$terms.id,]
order.partial=function(vec)
{
idx<-which(vec<=sort(vec,partial=21)[21])
idx[order(vec[idx])][2:21]
}
sums_2<-rowSums(m.poly^2)
dist_eucl<-sweep(sweep(-2*m.poly %*% t(m.poly),1,sums_2,"+"),2,sums_2,"+")
neighbors<-t(apply(dist_eucl,1,order.partial))
dim(dist_eucl)
dist_eucl<-sweep(sweep(-2*t(m.poly) %*% m.poly,1,sums_2,"+"),2,sums_2,"+")
sums_2<-colSums(m.poly^2)
dist_eucl<-sweep(sweep(-2*t(m.poly) %*% m.poly,1,sums_2,"+"),2,sums_2,"+")
neighbors<-t(apply(dist_eucl,1,order.partial))
dim(dist_eucl)
neighbors
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); a=(v %*% m)/(n * sqrt(sum(v^2)))
return(a)
}
a=matrix(c(1,2,3,4),nrow=2,ncol=2)
b=a=matrix(c(1,2,3,4),nrow=2,ncol=2)
a
b
cosinus.vm(a,b)
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); a=(t(v) %*% m)/(n * sqrt(colSums(v^2)))
return(a)
}
cosinus.vm(a,b)
t(a)
t(a)%*%b
a
b
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); a=(t(v) %*% m)/(n * sqrt(rowSums(v^2)))
return(a)
}
cosinus.vm(a,b)
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); a=(t(v) %*% m)#/(n * sqrt(rowSums(v^2)))
return(a)
}
cosinus.vm(a,b)
cosinus.vm <- function(v,m) {
n <- sqrt(rowSums(m^2)); a=(t(v) %*% m)/(n * sqrt(colSums(v^2)))
return(a)
}
cosinus.vm(a,b)
return(a)
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); a=(t(v) %*% m)/(n * sqrt(colSums(v^2)))
return(a)
}
cosinus.vm(a,b)
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); a=(t(v) %*% m)/(n * sqrt(rowSums(v^2)))
return(a)
}
cosinus.vm(a,b)
cosinus.vm <- function(v,m) {
n <- sqrt(rowSums(m^2)); a=(t(v) %*% m)/(n * sqrt(rowSums(v^2)))
return(a)
}
cosinus.vm(a,b)
cor(m.poly,m.poly)
cor(as.matrix(m.poly),as.matrix(m.poly))
rowSums(a)
colSums(b)
cbind(rowSums(a),colSums(b))
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2));k= sqrt(rowSums(v^2)); a=(t(v) %*% m)/cbind(k,n)
return(a)
}
cosinus.vm(a,b)
a
b
t(a)%*%b
sums2.TFIDF<-colSums(tf.idf^2)
dist.eucl.tfidf<-sweep(sweep(-2*t(tf.idf) %*% tf.idf,1,sums2.TFIDF,"+"),2,sums2.TFIDF,"+")
neighbors.tfidf<-t(apply(dist.eucl.tfidf,1,order.partial))
neighbors[1,]
neighbors.tfidf[1,]
sums2.ent<-colSums(log.entropy^2)
dist.eucl.ent<-sweep(sweep(-2*t(log.entropy) %*% log.entropy,1,sums2.ent,"+"),2,sums2.ent,"+")
neighbors.ent<-t(apply(dist.eucl.ent,1,order.partial))
neigbors[1,]
neighbors[1,]
neighbors.tfidf[1,]
neighbors.ent[1,]
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2));k= sqrt(rowSums(t(v^2))); p=(t(v) %*% m)/k; a=t(p)/n
return(a)
}
cosinus.vm(a,b)
cosinus.vm(m.poly,m.poly)
dim(cosinus.vm(m.poly,m.poly))
cosinus.tt <- cosinus.vm(m.poly,m.poly)
neighbors.tt <-t(apply(cosinus.tt,1,order.partial))
neighbors.tt[1,]
neighbors[1,]
View(courses.data)
courses.data.poly <-course.data[courses.data$university=='Poly',]
courses.data.poly <-courses.data[courses.data$university=='Poly',]
View(courses.data.poly)
courses.data.poly[neighbors,]
courses.data.poly[neighbors[1,],]
courses.data.poly[neighbors.tt[1,],]
cosinus.tt
max(cosinus.tt)
min(cosinus.tt)
dist_eucl
sum(cosinus.tt==t(cosinus.tt))
dim(cosinus.tt)
1168*1168
sum(dist_eucl==t(dist_eucl))
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
dim(lsaSpace.entropy)
dim(lsaSpace.entropy$tk)
dim(lsaSpace.entropy$sk)
dim(lsaSpace.entropy$dk)
length(lsaSpace.entropy$sk)
X.lsa <- lsaSpace.tfidf$tk %*% diag(lsaSpace.tfidf$sk) %*% t(lsaSpace.tfidf$dk)
sums2.lsa<-colSums(X.lsa^2)
dist.eucl.lsa<-sweep(sweep(-2*t(X.lsa) %*% x.lsa,1,sums2.lsa,"+"),2,sums2.lsa,"+")
dist.eucl.lsa<-sweep(sweep(-2*t(X.lsa) %*% X.lsa,1,sums2.lsa,"+"),2,sums2.lsa,"+")
neighbors.lsa<-t(apply(dist.eucl.lsa,1,order.partial))
neighbors.lsa[1,]
neighbors[1,]
X.lsa
dim(X.lsa)
X.lsa <- lsaSpace.tfidf$tk %*% diag(lsaSpace.tfidf$sk)# %*% t(lsaSpace.tfidf$dk)
sums2.lsa<-colSums(X.lsa^2)
dist.eucl.lsa<-sweep(sweep(-2*t(X.lsa) %*% X.lsa,1,sums2.lsa,"+"),2,sums2.lsa,"+")
neighbors.lsa<-t(apply(dist.eucl.lsa,1,order.partial))
dim(X.lsa)
neighbors.lsa[1,]
X.lsa <- lsaSpace.tfidf$tk %*% diag(lsaSpace.tfidf$sk) %*% t(lsaSpace.tfidf$dk)
dim(m.poly)
dim(X.lsa)
m.poly[1,]
m.poly[,1]
m.poly[1:30,1]
X.lsa[1:30,1]
max(X.lsa)
tf.idf[1:30,1]
max(tf.idf)
log.entropy[1:30,1]
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
neighbors.lsa[1,]
courses.data.poly[neighbors.lsa[1,],]
courses.data.poly[neighbors[1,],]
courses.data.poly[neighbors.tfidf[1,],]
courses.data.poly[55,]
courses.data.poly[450,]
courses.data.poly[neighbors.tfidf[50,],]
courses.data.poly[neighbors.lsa[50,],]
courses.data.poly[neighbors.lsa[450,],]
courses.data.poly[450,]
courses.data.poly[neighbors.lsa[450,],]
courses.data.poly[30,]
courses.data.poly[40,]
courses.data.poly[35,]
courses.data.poly[20,]
courses.data.poly[22,]
courses.data.poly[23,]
courses.data.poly[neighbors.lsa[23,],]
courses.data.poly[neighbors.tfidf[23,],]
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
id.hec <- which(courses.data$universtity=="hec")
id.hec <- which(courses.data$universtity=="HEC")
View(courses.data)
id.hec <- which(courses.data$universtity=="HEC ")
id.poly <- which(courses.data$university=="Poly")
id.hec <- which(courses.data$universtity=="HEC")
id.udm <- which(courses.data$university== "UdM")
id.udm <- which(courses.data$university== "Ud")
id.udm <- which(courses.data$university== "UdM")
id.hec <- which(courses.data$universtity=="HEC")
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
mydir <- "C:/Users/claudedb/Documents/Polymtl/LOG6308/Project/cours-mtl (1)/desc-cours"
essai <- textmatrix( mydir, stemming=FALSE, language="french", minWordLength=2, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
mydir <- "Desktop/essai"
essai <- textmatrix( mydir, stemming=FALSE, language="french", minWordLength=2, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
mydir <- "C:/Users/claudedb/Desktop/essai"
essai <- textmatrix( mydir, stemming=FALSE, language="french", minWordLength=2, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
essai
essai <- textmatrix( mydir, stemming=TRUE, language="french", minWordLength=2, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
essai
essai <- textmatrix( mydir, stemming=TRUE, language="french", minWordLength=2, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
essai.not <- textmatrix( mydir, stemming=FALSE, language="french", minWordLength=2, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
essai <- textmatrix( mydir, stemming=TRUE, language="french", minWordLength=4, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
essai.not <- textmatrix( mydir, stemming=FALSE, language="french", minWordLength=4, maxWordLength=FALSE, minDocFreq=1,  maxDocFreq=FALSE, minGlobFreq=FALSE, maxGlobFreq=FALSE,  stopwords=NULL, vocabulary=NULL, phrases=NULL,  removeXML=FALSE, removeNumbers=FALSE)
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
source('~/GitHub/RecSys/Project/ProjetCode.R', echo=TRUE)
essai <- m.poly%*%m.poly
essai <- m.poly%*%t(m.poly)
dim(essai)
essai <- t(m.poly)%*%m.poly
dim(essai)
neighbors.ps <- t(apply(essai,1,order.partial))
neighbors.ps[1,]
neighbors[1,]
courses.data.poly[neighbors[1,],]
courses.data.poly[neighbors.ps[1,],]
