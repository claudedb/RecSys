1+1
help(qunif)
qunif(1)
qunif(1=0.75)
qunif(0.75)
install.packages('xgboost')
source('~/Polymtl/LOG6308/clustering.R', echo=TRUE)
dim(dist_eucl)
clusters<-hclust(dist_eucl,method='complete')
View(dist_eucl)
dist_eucl<-sqrt(sweep(sweep(-2*m %*% t(m),1,sums_2,"+"),2,sums_2,"+"))
clusters<-hclust(dist_eucl,method='complete')
clusters<-hclust(as.dist(dist_eucl),method='complete')
clusters
try<-cutree(clusters, k = 10)
try
clusters<-hclust(as.dist(dist_eucl),method='centroid')
try<-cutree(clusters, k = 10)
try
clusters<-hclust(as.dist(dist_eucl))
try<-cutree(clusters, k = 10)
try
dist_eucl<-matrix.cos(m)
matrix.cos <- function(m) {
(m %*% t(m)) / ( t(matrix(sqrt(rowSums(m^2)),nrow(m),nrow(m)))
* (sqrt(rowSums(m^2))) )
}
sums_2<-rowSums(m^2)
dist_eucl<-matrix.cos(m)
clusters<-hclust(as.dist(dist_eucl))
try<-cutree(clusters, k = 10)
try
avg.user<-rowSums(m)/rowSums(m>0)
m.class<-cbind(calc.clusters,m)
calc.clusters<-cutree(clusters, k = 10)
m.class<-cbind(calc.clusters,m)
View(m.class)
clusters.avg<-aggregate(.~calc.clusters,m.class,mean())
clusters.avg<-aggregate(.~calc.clusters,m.class,'mean')
m.class<-as.dataframe(cbind(calc.clusters,m))
m.class<-as.data.frame(cbind(calc.clusters,m))
clusters.avg<-aggregate(.~calc.clusters,m.class,'mean')
View(clusters.avg)
clusters.avg<-aggregate(.~calc.clusters,m.class,'sum')/aggregate(.~calc.clusters,m.class>0,'sum')
View(m.class)
m.class[m.class==0]<-NA
clusters.avg<-aggregate(.~calc.clusters,m.class,'mean')
mean.nona<-function(m){
return(mean(m,na.rm=T))
}
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean.nona')
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
calc.clusters<-cutree(clusters, k = 10)
m.class<-as.data.frame(cbind(calc.clusters,m))
m.class[m.class==0]<-NA
mean.nona<-function(m){
return(mean(m,na.rm=T))
}
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
m.class<-as.data.frame(cbind(calc.clusters,m))
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
m.class[m.class==0]<-NA
View(m.class)
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.action=na.omit)
clusters.avg<-aggregate(.~calc.clusters,m.class,FUN='mean',na.rm=T,na.action=NULL)
View(clusters.avg)
is.nan(clusters.avg)<-NA
is.nan(clusters.avg)
source('~/GitHub/LOG6308/TP 2/TP2-V1.R', echo=TRUE)
which(m[doc.id.q1,]==1)
s
S
SS<-colSums(which(m[doc.id.q1,]==1))
SS<-colSums(m[which(m[doc.id.q1,]==1),])
ss
SS
SS<-colSums(m[which(m[doc.id.q1,]==1),])+m[,doc.id.q1]
SS<-colSums(m[which(m[doc.id.q1,]==1),])+m[doc.id.q1,]
SS[SS>=1]<-1
ref.ref.PR<-S.prime*PageRank
S.prime<-colSums(m[which(m[doc.id.q1,]==1),])+m[doc.id.q1,]
S.prime[S.prime>=1]<-1
ref.ref.PR<-S.prime*PageRank
m[doc.id.q1,]
RR.PageRank<-S.prime*PageRank
RR.PageRank<-S.prime*PageRank
recommendations.RR<-RR.PageRank[order(-recommendations.RR)][1:10]
recommendations.RR<-RR.PageRank[order(-RR.PageRank)][1:10]
colnames(recommendations.RR)
colnames(recommendations.references)
S
references.PageRank<-m[doc.id.q1,]*PageRank
recommendations.references<-references.PageRank[order(-references.PageRank)][1:10]
colnames(recommendations.references)
S.prime<-colSums(m[which(m[doc.id.q1,]==1),])+m[doc.id.q1,]
S.prime[S.prime>=1]<-1
RR.PageRank<-S.prime*PageRank
recommendations.RR<-RR.PageRank[order(-RR.PageRank)][1:10]
colnames(recommendations.RR)
colnames(recommendations.references)
vecteur.q2<-m[,doc.id.q1]
vecteur.q2<-m[,"x"+doc.id.q1]
doc.id.q2<-"X"+doc.id.q1
doc.id.q2<-paste("X",doc.id.q1)
doc.id.q2<-paste("X",doc.id.q1,sep="")
vecteur.q2<-m[,doc.id.q2]
positions.votes.communs=(m[,doc.id.q2]*m)>0
positions.votes.communs<-(m[,doc.id.q2]*m)>0
votes.communs<-(colSums((m[,doc.id.q2]*m)>0,na.rm=T))
doc.id.q2<-paste("X",doc.id.q1,sep="")
vecteur.q2<-m[,doc.id.q2]
#On identifie d'abord avec une matrice logique les positions des votes communs avec l'article actuel
positions.votes.communs<-(m[,doc.id.q2]*m)>0
#votes.communs est un vecteur de longueur 1090 où chaque instance représente le nombre de votes communs avec l'article actuel.
votes.communs<-(colSums((m[,doc.id.q2]*m)>0,na.rm=T))
k<-vecteur.q2%*%m
m.clean<-m
m.clean[!positions.votes.communs]<-NA
vecteur.q2.clean<-vecteur.q2
vecteur.q2.clean<-matrix(vecteur.q2.clean,nrow=dim(m)[1],ncol=dim(m)[2])
vecteur.q2.clean<-as(vecteur.q2.clean, "dgCMatrix")
vecteur.q2.clean[!positions.votes.communs]=NA
n=sqrt(colSums(m.clean^2,na.rm=T))
d=sqrt(colSums(vecteur.q2.clean^2,na.rm=T))
cosinus.q2<-k/(n*d)
cosinus.q2<-as.vector(cosinus.q2)
cosinus.q2[is.nan(cosinus.q2)]<-0
#Paramètre à modifier parce que si il n'est pas là, tous les articles avec les plus hauts cosinus sont ceux
#qui n'ont pas beaucoup de votes communs et que les votes sont très similaires
cosinus.q2.VC<-cosinus.q2
#cosinus.q2.VC[votes.communs<=15]<-NA
distance.ii<-sqrt(colSums((m.clean-vecteur.q3)^2,na.rm=T))/votes.communs
distance.ii[votes.communs<5]<-NA
#On sélectionne les 20 items les plus proches et
distance.top20.ii<-min.nindex(distance.ii,21)
distance.top20.ii<-distance.top20.ii[distance.top20.ii!=q2.id]
cosinus.q3=cosinus.q2[distance.top20.ii]
#On apporte une pondération fonction du nombre de votes communs avec Star trek
cosinus.q2.VC=(pmax(votes.communs[distance.top20.ii],5)/5)*cosinus.q2[distance.top20.ii]
facteur.k<-1/sum(abs(cosinus.q2.VC),na.rm=T)
avg.article<-sum(m[,doc.id.q2])/sum(m[,doc.id.q2]>0)
#m.estim représente la matrice m qu'on a filtré avec les 20 plus proches voisins, elle est donc de dimension 1090x20.
m.estim<-m
m.estim[m.estim==0]<-NA
m.estim<-m.estim[,distance.top20.ii]
#Calcul de l'Estimation du vote basé sur les plus proches voisins
ecart=t(t(m.estim)-colMeans(m.estim,na.rm=T))
ecart.mat=as.matrix(ecart)
terme=t(t(ecart.mat)*cosinus.q2.VC)
#On prédit même pour ceux ayant déjà un vote pour l'article
estimation=avg.startrek+facteur.k*rowSums(terme,na.rm=T)
#On donne une valeur manquante aux users qui n'ont pas de votes communs avec les 20 plus proches voisins du film actuel
estimation[which(rowSums(m.estim,na.rm=T)==0)]=NA
doc.id.q2<-paste("X",doc.id.q1,sep="")
vecteur.q2<-m[,doc.id.q2]
positions.votes.communs<-(m[,doc.id.q2]*m)>0
votes.communs<-(colSums((m[,doc.id.q2]*m)>0,na.rm=T))
k<-vecteur.q2%*%m
k<-vecteur.q2%*%as.matrix(m)
m.clean<-as.matrix(m)
m.clean[!positions.votes.communs]<-NA
vecteur.q2.clean<-vecteur.q2
vecteur.q2.clean<-matrix(vecteur.q2.clean,nrow=dim(m)[1],ncol=dim(m)[2])
vecteur.q2.clean<-as(vecteur.q2.clean, "dgCMatrix")
vecteur.q2.clean[!positions.votes.communs]=NA
n=sqrt(colSums(m.clean^2,na.rm=T))
d=sqrt(colSums(vecteur.q2.clean^2,na.rm=T))
cosinus.q2<-k/(n*d)
cosinus.q2<-as.vector(cosinus.q2)
cosinus.q2[is.nan(cosinus.q2)]<-0
cosinus.q2.VC<-cosinus.q2
distance.ii<-sqrt(colSums((m.clean-vecteur.q3)^2,na.rm=T))/votes.communs
distance.ii<-sqrt(colSums((m.clean-vecteur.q2)^2,na.rm=T))/votes.communs
distance.ii[votes.communs<5]<-NA
distance.top20.ii<-min.nindex(distance.ii,21)
distance.top20.ii<-distance.top20.ii[distance.top20.ii!=q2.id]
cosinus.q2<-cosinus.q2[distance.top20.ii]
cosinus.q2.VC=(pmax(votes.communs[distance.top20.ii],5)/5)*cosinus.q2[distance.top20.ii]
facteur.k<-1/sum(abs(cosinus.q2.VC),na.rm=T)
avg.article<-sum(m[,doc.id.q2])/sum(m[,doc.id.q2]>0)
m.estim<-as.matrix(m)
m.estim[m.estim==0]<-NA
m.estim<-m.estim[,distance.top20.ii]
ecart=t(t(m.estim)-colMeans(m.estim,na.rm=T))
ecart.mat=as.matrix(ecart)
terme=t(t(ecart.mat)*cosinus.q2.VC)
estimation=avg.article+facteur.k*rowSums(terme,na.rm=T)
estimation[which(rowSums(m.estim,na.rm=T)==0)]=NA
estimation
cosinus.q2
cosinus.q2<-cosinus.vm(vecteur.q2,m)
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2)); (v %*% m)/(n * sqrt(sum(v^2)))
return(n)
}
cosinus.q2<-cosinus.vm(vecteur.q2,m)
cosinus.q2<-cosinus.vm(vecteur.q2,as.matrix(m))
recommendations.ii<-cosinus.q2[order(-cosinus.q2)][1:10]
colnames(cosinus.q2)
cosinus.q2
colnames(recommendations.ii)
recommendations.ii<-cosinus.q2[order(-cosinus.q2)][1:10]
rownames(recommendations.ii)
recommendations.ii
recommendations.ii[1,]
colnames(recommendations.ii)
colnames(data.frame(recommendations.ii))
data.frame(recommendations.ii)
rownames(data.frame(recommendations.ii))
colnames(recommendations.RR)
colnames(recommendations.references)
source('~/GitHub/RecSys/TP 3/TP3.R', echo=TRUE)
essai<-sapply(seed,cross.validation,pct=0.9)
essai
RMSE.q6$RMSE<-rowMeans(essai)
g2<-ggplot(RMSE.q6,aes(x=dimension))+
geom_point(aes(y=RMSE))
g2
RMSE.q6V<-sapply(seed,cross.validation,pct=0.9,error.type='RMSE')
MAE.q6V<-sapply(seed,cross.validation,pct=0.9,error.type='MAE')
RMSE.q6$RMSE<-rowMeans(RMSE.q6V)
RMSE.q6$MAE<-rowMeans(MAE.q6V)
g2<-ggplot(RMSE.q6,aes(x=dimension))+
geom_point(aes(y=RMSE))+
geom_point(aes(y=MAE),fill='red')
RMSE.q6V<-sapply(seed,cross.validation,pct=0.9,error.type='RMSE')
RMSE.q6V<-sapply(seed,cross.validation,pct=0.9,error.type='RMSE')
SVD.cv=function (i,error.type)
{
#print(i)
Si<-sqrt(S.q6[1:i,1:i])
Ui<-U.q6[,1:i]
Vi<-V.q6[,1:i]
m.pred.q6<-m.moy.q6+(Ui%*%t(Si))%*%Si%*%t(Vi)
if(error.type=='RMSE'){
RMSE.q6<-sqrt(mean(as.matrix((m.test-m.pred.q6)^2),na.rm=TRUE))
return(RMSE.q6)
}
else if(error.type=='MAE'){
MAE.q6<-mean(as.matrix(abs(m.test-m.pred.q6)),na.rm=TRUE)
}
else
{
return(0)
}
}
cross.validation = function (k,pct,error.type){
set.seed(k)
j<-m>0
j.test<-j
#table(as.vector(j.test),useNA='always')
j.test[sample(length(j),pct*length(j))]<-FALSE
#table(j.test,useNA='always')
j.train<-!j.test
m.test<-m.NA
m.train<-m.NA
m.train[j.test]<-NA
m.test[!j.test]<-NA
moy.row.train<-rowSums(m.train,na.rm=TRUE)/rowSums(m>0,na.rm = TRUE)
m.norm.q6<-m.train-moy.row.train
m.norm.q6[is.na(m.norm.q6)]<-0
m.norm.q6<-Matrix(m.norm.q6, sparse=TRUE)
SVD.q6<-svd(m.norm.q6)
S.q6<-SVD.q6$d
S.q6<-diag(S.q6)
U.q6<-SVD.q6$u
V.q6<-SVD.q6$v
m.moy.q6<-m.train
m.moy.q6[]<-0
m.moy.q6<-sweep(m.moy.q6,1,moy.row.train,'+')
SVD.cv=function (i,error.type)
{
#print(i)
Si<-sqrt(S.q6[1:i,1:i])
Ui<-U.q6[,1:i]
Vi<-V.q6[,1:i]
m.pred.q6<-m.moy.q6+(Ui%*%t(Si))%*%Si%*%t(Vi)
if(error.type=='RMSE'){
RMSE.q6<-sqrt(mean(as.matrix((m.test-m.pred.q6)^2),na.rm=TRUE))
return(RMSE.q6)
} else if(error.type=='MAE'){
MAE.q6<-mean(as.matrix(abs(m.test-m.pred.q6)),na.rm=TRUE)
} else{
return(0)
}
}
result.SVD.q6<-sapply(RMSE.q6$dimension,SVD.cv,error.type=error.type)
return(result.SVD.q6)
}
RMSE.q6V<-sapply(seed,cross.validation,pct=0.9,error.type='RMSE')
MAE.q6V<-sapply(seed,cross.validation,pct=0.9,error.type='MAE')
RMSE.q6$RMSE<-rowMeans(RMSE.q6V)
RMSE.q6$MAE<-rowMeans(MAE.q6V)
g2<-ggplot(RMSE.q6,aes(x=dimension))+
geom_point(aes(y=RMSE))+
geom_point(aes(y=MAE),fill='red')
g2
View(RMSE.q6)
seed.q7<-c(55,75,95,105,222,60,78,4,6,23)
n_fold.q7<-length(seed.q7)
error.q7<-data.frame(seed=seed.q7,RMSE.SVD=rep(0,n_fold.q7),
MAE.SVD=rep(0,n_fold.q7),RMSE.ii=rep(0,n_fold.q7),MAE.ii=rep(0,n_fold.q7))
cross.validation.SVD7 = function (k,pct,error.type){
set.seed(k)
j<-m>0
j.test<-j
#table(as.vector(j.test),useNA='always')
j.test[sample(length(j),pct*length(j))]<-FALSE
#table(j.test,useNA='always')
j.train<-!j.test
m.test<-m.NA
m.train<-m.NA
m.train[j.test]<-NA
m.test[!j.test]<-NA
moy.row.train<-rowSums(m.train,na.rm=TRUE)/rowSums(m>0,na.rm = TRUE)
m.norm.q6<-m.train-moy.row.train
m.norm.q6[is.na(m.norm.q6)]<-0
m.norm.q6<-Matrix(m.norm.q6, sparse=TRUE)
SVD.q6<-svd(m.norm.q6)
S.q6<-SVD.q6$d
S.q6<-diag(S.q6)
U.q6<-SVD.q6$u
V.q6<-SVD.q6$v
m.moy.q6<-m.train
m.moy.q6[]<-0
m.moy.q6<-sweep(m.moy.q6,1,moy.row.train,'+')
SVD.cv=function (i=10,error.type)
{
#print(i)
Si<-sqrt(S.q6[1:i,1:i])
Ui<-U.q6[,1:i]
Vi<-V.q6[,1:i]
m.pred.q6<-m.moy.q6+(Ui%*%t(Si))%*%Si%*%t(Vi)
if(error.type=='RMSE'){
RMSE.q6<-sqrt(mean(as.matrix((m.test-m.pred.q6)^2),na.rm=TRUE))
return(RMSE.q6)
} else if(error.type=='MAE'){
MAE.q6<-mean(as.matrix(abs(m.test-m.pred.q6)),na.rm=TRUE)
} else{
return(0)
}
}
result.SVD.q6<-sapply(10,SVD.cv,error.type=error.type)
return(result.SVD.q6)
}
RMSE.SVD7<-sapply(seed.q7,cross.validation.SVD7,pct=0.9,error.type='RMSE')
MAE.SVD7<-sapply(seed.q7,cross.validation.SVD7,pct=0.9,error.type='MAE')
